{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11739476,"sourceType":"datasetVersion","datasetId":7369721},{"sourceId":11755699,"sourceType":"datasetVersion","datasetId":7380024},{"sourceId":11756706,"sourceType":"datasetVersion","datasetId":7380611},{"sourceId":11767721,"sourceType":"datasetVersion","datasetId":7387694}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install underthesea\nimport os\nos.environ[\"WANDB_MODE\"] = \"disabled\"\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T09:54:17.973112Z","iopub.execute_input":"2025-05-11T09:54:17.973664Z","iopub.status.idle":"2025-05-11T09:54:23.605089Z","shell.execute_reply.started":"2025-05-11T09:54:17.973639Z","shell.execute_reply":"2025-05-11T09:54:23.604379Z"}},"outputs":[{"name":"stdout","text":"Collecting underthesea\n  Downloading underthesea-6.8.4-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from underthesea) (8.1.8)\nCollecting python-crfsuite>=0.9.6 (from underthesea)\n  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from underthesea) (3.9.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from underthesea) (4.67.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from underthesea) (2.32.3)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from underthesea) (1.4.2)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from underthesea) (1.2.2)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from underthesea) (6.0.2)\nCollecting underthesea-core==1.0.4 (from underthesea)\n  Downloading underthesea_core-1.0.4-cp311-cp311-manylinux2010_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->underthesea) (2024.11.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->underthesea) (2025.1.31)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (1.15.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->underthesea) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn->underthesea) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->underthesea) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn->underthesea) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn->underthesea) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn->underthesea) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn->underthesea) (2024.2.0)\nDownloading underthesea-6.8.4-py3-none-any.whl (20.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading underthesea_core-1.0.4-cp311-cp311-manylinux2010_x86_64.whl (657 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: underthesea-core, python-crfsuite, underthesea\nSuccessfully installed python-crfsuite-0.9.11 underthesea-6.8.4 underthesea-core-1.0.4\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm.notebook import tqdm\nfrom scipy.sparse import csr_matrix, save_npz\n\n# === CONFIG ===\nVOCAB_PATH = '/kaggle/input/datanlpnew/vocabulary.csv'  # word, idf, pos\nTRAIN_PATH = '/kaggle/input/datanlpnew/train_set.csv'\nSAVE_PATH = './bm42_attention_weights.npz'\nEPOCHS = 21\n\n# --- Load vocab ---\nvocab_df = pd.read_csv(VOCAB_PATH)\nvocab = vocab_df['word'].tolist()\nidf = vocab_df['idf'].values\npos = vocab_df['pos'].tolist()\nword2idx = {w: i for i, w in enumerate(vocab)}\nvocab_size = len(vocab)\n\n# POS multiplier\npos_multiplier = np.array([1.5 if p in ('N', 'V') else 1.0 for p in pos], dtype=np.float32)\n\n# --- Model ---\nclass BM42Attn(nn.Module):\n    def __init__(self, init_weights):\n        super().__init__()\n        self.attn = nn.Parameter(torch.tensor(init_weights, dtype=torch.float32))\n    def forward(self, idxs):\n        return self.attn[idxs]\n\n# --- Data ---\ndef get_doc_tokens(row, col, vocab_set):\n    return [w for w in str(row[col]).split() if w in vocab_set]\n\ndef get_q_idxs(row, col, word2idx):\n    return [word2idx[w] for w in str(row[col]).split() if w in word2idx]\n\ndef get_relevant_cids(row):\n    return [int(cid) for cid in str(row['cid']).split(',') if cid.strip().isdigit()]\n\ntrain_df = pd.read_csv(TRAIN_PATH)\nvocab_set = set(vocab)\n\n# Precompute all doc tokens for fast negatives (train only)\ndoc_tokens = {}\nfor _, row in train_df.iterrows():\n    doc_tokens[int(str(row['cid']).split(',')[0])] = get_doc_tokens(row, 'context_tokenized', vocab_set)\n\n# --- Training ---\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ninit_weights = np.clip(np.ones(vocab_size, dtype=np.float32), 0.01, 1.99)\nmodel = BM42Attn(init_weights).to(device)\noptimizer = optim.Adam([model.attn], lr=0.03)\n\ndef bm42_score(q_idxs, doc, model, idf, pos_multiplier):\n    doc_set = set(doc)\n    idxs_in_doc = [i for i in q_idxs if vocab[i] in doc_set]\n    idxs_in_doc_tensor = torch.tensor(idxs_in_doc, dtype=torch.long, device=device)\n    if len(idxs_in_doc_tensor) == 0:\n        return (model.attn[0:0] * torch.tensor([], dtype=torch.float32, device=device)).sum()\n    attn = model(idxs_in_doc_tensor)\n    idf_tensor = torch.tensor(idf[idxs_in_doc], dtype=torch.float32, device=device)\n    pos_mult_tensor = torch.tensor(pos_multiplier[idxs_in_doc], dtype=torch.float32, device=device)\n    return (attn * idf_tensor * pos_mult_tensor).sum()\n\nfor epoch in range(EPOCHS):\n    model.train()\n    losses = []\n    for _, row in tqdm(train_df.iterrows(), total=len(train_df), desc=f\"Epoch {epoch+1}\"):\n        q_idxs = get_q_idxs(row, 'question_tokenized', word2idx)\n        if not q_idxs:\n            continue\n        rel_cids = get_relevant_cids(row)\n        if not rel_cids:\n            continue\n        pos_doc = get_doc_tokens(row, 'context_tokenized', vocab_set)\n        # Negative: sample a random doc not in rel_cids\n        neg_cid = np.random.choice([cid for cid in doc_tokens if cid not in rel_cids])\n        neg_doc = doc_tokens[neg_cid]\n        pos_score = bm42_score(q_idxs, pos_doc, model, idf, pos_multiplier)\n        neg_score = bm42_score(q_idxs, neg_doc, model, idf, pos_multiplier)\n        margin = 1.0\n        loss = torch.clamp(margin - (pos_score - neg_score), min=0)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        with torch.no_grad():\n            model.attn.data.clamp_(0.01, 1.99)\n        losses.append(loss.detach().cpu().item())\n    print(f\"Epoch {epoch+1} mean loss: {np.mean(losses):.4f}\")\n    # Decay learning rate every 3 epochs\n    if (epoch + 1) % 3 == 0:\n        for param_group in optimizer.param_groups:\n            param_group['lr'] *= 0.9\n        print(f\"Learning rate decayed to {optimizer.param_groups[0]['lr']:.6f}\")\n    # Save (overwrite) after every epoch\n    weights_np = model.attn.detach().cpu().numpy()\n    sparse_weights = csr_matrix(weights_np.reshape(1,-1))\n    save_npz(SAVE_PATH, sparse_weights)\n    print(f\"Saved model to {SAVE_PATH}\")\n\nprint(\"Training complete.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy.sparse import load_npz, csr_matrix\nfrom tqdm.notebook import tqdm\nfrom collections import defaultdict\n\n# File paths\nTEST_PATH = '/kaggle/input/datanlpnew/test_set.csv'\nCORPUS_PATH = '/kaggle/input/datanlpnew/corpus_tokenized.csv'\nVOCAB_PATH = '/kaggle/input/datanlpnew/vocabulary.csv'\nBM42_WEIGHTS_PATH = '/kaggle/input/bm4222/bm42_attention_weights.npz'\n\n# Load test set, corpus, and vocabulary\nprint(\"Loading data...\")\ntest_df = pd.read_csv(TEST_PATH)\ncorpus_df = pd.read_csv(CORPUS_PATH)\nvocab_df = pd.read_csv(VOCAB_PATH)\n\n# Load BM42 attention weights\nprint(\"Loading BM42 weights...\")\nbm42_weights = load_npz(BM42_WEIGHTS_PATH).toarray()[0]  # Convert from sparse to dense\n\n# Create word-to-index mapping and get IDF values\nvocab = vocab_df['word'].tolist()\nidf = vocab_df['idf'].values\npos = vocab_df['pos'].tolist()\nword2idx = {w: i for i, w in enumerate(vocab)}\n\n# Apply POS multiplier to attention weights\npos_multiplier = np.array([1.5 if p in ('N', 'V') else 1.0 for p in pos], dtype=np.float32)\nattention_weights = bm42_weights * pos_multiplier\n\n# Pre-compute weighted IDF values\nweighted_idf = attention_weights * idf\n\n# ---- OPTIMIZATION 1: Create inverted index ----\nprint(\"Building inverted index...\")\ninverted_index = defaultdict(list)\ncorpus_docs = {}\ncorpus_ids = []\n\nfor _, row in tqdm(corpus_df.iterrows(), total=len(corpus_df)):\n    cid = int(row['cid'])\n    corpus_ids.append(cid)\n    tokens = str(row['context_tokenized']).split()\n    # Filter and keep only tokens in vocabulary\n    valid_tokens = [t for t in tokens if t in word2idx]\n    corpus_docs[cid] = set(valid_tokens)  # Store as set for O(1) lookups\n    \n    # Build inverted index: for each token, store which documents contain it\n    for token in set(valid_tokens):  # Use set to avoid duplicates\n        inverted_index[token].append(cid)\n\n# ---- OPTIMIZATION 2: Vectorized BM42 scoring ----\ndef fast_bm42_evaluate(test_df, corpus_docs, inverted_index, weighted_idf, word2idx, k_values=[5, 10, 20]):\n    mrr_total = 0.0\n    accuracy = {k: 0 for k in k_values}\n    total_queries = 0\n    \n    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Evaluating\"):\n        query_tokens = str(row['question_tokenized']).split()\n        query_tokens = [t for t in query_tokens if t in word2idx]\n        \n        if not query_tokens:\n            continue\n            \n        # Get relevant document IDs for this query\n        try:\n            relevant_cids = set(int(cid) for cid in str(row['cid']).split(','))\n        except ValueError:\n            continue\n        \n        # ---- OPTIMIZATION 3: Only score documents that contain at least one query term ----\n        candidate_docs = set()\n        for token in query_tokens:\n            if token in inverted_index:\n                candidate_docs.update(inverted_index[token])\n        \n        # If no candidates found, skip this query\n        if not candidate_docs:\n            continue\n            \n        # Score only candidate documents (not the entire corpus)\n        scores = []\n        for cid in candidate_docs:\n            score = 0.0\n            doc_tokens = corpus_docs[cid]\n            \n            # Sum weighted IDF for matching tokens\n            for token in query_tokens:\n                if token in doc_tokens:\n                    idx = word2idx[token]\n                    score += weighted_idf[idx]\n                    \n            scores.append((cid, score))\n            \n        # Sort by score (descending)\n        scores.sort(key=lambda x: x[1], reverse=True)\n        \n        # Calculate metrics\n        rank = float('inf')\n        for i, (cid, _) in enumerate(scores):\n            if cid in relevant_cids:\n                rank = i + 1\n                break\n                \n        # Update MRR if a relevant document was found\n        if rank < float('inf'):\n            mrr_total += 1.0 / rank\n            \n        # Update accuracy@k\n        for k in k_values:\n            top_k_cids = [cid for cid, _ in scores[:k]]\n            if any(cid in relevant_cids for cid in top_k_cids):\n                accuracy[k] += 1\n                \n        total_queries += 1\n    \n    # Calculate final metrics\n    mrr = mrr_total / total_queries if total_queries > 0 else 0\n    accuracy = {k: acc / total_queries if total_queries > 0 else 0 for k, acc in accuracy.items()}\n    \n    return mrr, accuracy, total_queries\n\n# Run evaluation with optimized function\nprint(\"Starting optimized evaluation...\")\nmrr, accuracy, total_queries = fast_bm42_evaluate(\n    test_df, \n    corpus_docs, \n    inverted_index, \n    weighted_idf, \n    word2idx\n)\n\n# Print results\nprint(f\"\\n===== BM42 Evaluation Results (Total Queries: {total_queries}) =====\")\nprint(f\"MRR: {mrr:.4f}\")\nfor k, acc in accuracy.items():\n    print(f\"Accuracy@{k}: {acc:.4f}\")                                 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T08:30:06.433707Z","iopub.execute_input":"2025-05-11T08:30:06.434211Z","iopub.status.idle":"2025-05-11T09:37:51.219725Z","shell.execute_reply.started":"2025-05-11T08:30:06.434188Z","shell.execute_reply":"2025-05-11T09:37:51.218850Z"}},"outputs":[{"name":"stdout","text":"Loading data...\nLoading BM42 weights...\nBuilding inverted index...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/68663 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb6efaa1cde34cdeb038498c31a87e37"}},"metadata":{}},{"name":"stdout","text":"Starting optimized evaluation...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/23892 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"921b294e79f24e2bb741651dca75c54f"}},"metadata":{}},{"name":"stdout","text":"\n===== BM42 Evaluation Results (Total Queries: 23892) =====\nMRR: 0.3742\nAccuracy@5: 0.5130\nAccuracy@10: 0.6090\nAccuracy@20: 0.6961\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy.sparse import load_npz\nfrom underthesea import word_tokenize\nfrom collections import defaultdict\n\nCORPUS_PATH = '/kaggle/input/datanlpnew/corpus_tokenized.csv'\nVOCAB_PATH = '/kaggle/input/datanlpnew/vocabulary.csv'\nBM42_WEIGHTS_PATH = '/kaggle/input/bm4222/bm42_attention_weights.npz'\n\ncorpus_df = pd.read_csv(CORPUS_PATH)\nvocab_df = pd.read_csv(VOCAB_PATH)\nbm42_weights = load_npz(BM42_WEIGHTS_PATH).toarray().flatten()\n\nvocab = vocab_df['word'].tolist()\nidf = vocab_df['idf'].values\npos = vocab_df['pos'].tolist()\nword2idx = {w: i for i, w in enumerate(vocab)}\nvocab_set = set(vocab)\npos_multiplier = np.array([1.5 if p in ('N', 'V') else 1.0 for p in pos], dtype=np.float32)\nattention_weights = bm42_weights * pos_multiplier\n\ninverted_index = defaultdict(list)\ncorpus_docs = {}\ncorpus_texts = {}\n\nfor _, row in corpus_df.iterrows():\n    cid = int(row['cid'])\n    tokens = str(row['context_tokenized']).split()\n    valid_tokens = [t for t in tokens if t in vocab_set]\n    corpus_docs[cid] = set(valid_tokens)\n    corpus_texts[cid] = str(row['context_tokenized'])\n    for token in set(valid_tokens):\n        inverted_index[token].append(cid)\n\ndef search_documents(query, top_k=20):\n    tokenized_query = word_tokenize(query)\n    if isinstance(tokenized_query, list):\n        tokenized_query = ' '.join(tokenized_query)\n    print(f\"Tokenized query: {tokenized_query}\")\n    query_tokens = [t for t in tokenized_query.split() if t in vocab_set]\n    if not query_tokens:\n        print(\"No query tokens found in vocabulary.\")\n        return []\n    candidate_docs = set()\n    for token in query_tokens:\n        if token in inverted_index:\n            candidate_docs.update(inverted_index[token])\n    if not candidate_docs:\n        print(\"No matching documents found.\")\n        return []\n    scores = []\n    for cid in candidate_docs:\n        score = 0.0\n        doc_tokens = corpus_docs[cid]\n        for token in query_tokens:\n            if token in doc_tokens:\n                idx = word2idx[token]\n                score += attention_weights[idx] * idf[idx]\n        scores.append((cid, score))\n    scores.sort(key=lambda x: x[1], reverse=True)\n    results = []\n    for cid, score in scores[:top_k]:\n        results.append({\n            'cid': cid,\n            'score': score,\n            'text': corpus_texts[cid]\n        })\n    return results\n\nexample_query = \"phó tổng giám đốc ngân hàng chính sách xã hội được xếp lương theo bảng lương như thế nào\"\nprint(f\"\\nExample query: '{example_query}'\")\nresults = search_documents(example_query)\nprint(f\"\\nTop {len(results)} results:\")\nfor i, doc in enumerate(results):\n    print(f\"\\n{i+1}. Document ID: {doc['cid']}\")\n    print(f\"   Score: {doc['score']:.4f}\")\n    preview = doc['text'][:200] + \"...\" if len(doc['text']) > 200 else doc['text']\n    print(f\"   Preview: {preview}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T10:05:08.465155Z","iopub.execute_input":"2025-05-11T10:05:08.465523Z","iopub.status.idle":"2025-05-11T10:05:20.200622Z","shell.execute_reply.started":"2025-05-11T10:05:08.465500Z","shell.execute_reply":"2025-05-11T10:05:20.199855Z"}},"outputs":[{"name":"stdout","text":"\nExample query: 'phó tổng giám đốc ngân hàng chính sách xã hội được xếp lương theo bảng lương như thế nào'\nTokenized query: phó tổng giám đốc ngân hàng chính sách xã hội được xếp lương theo bảng lương như thế nào\n\nTop 20 results:\n\n1. Document ID: 8169\n   Score: 42.1669\n   Preview: điều phạm_vi và đối_tượng phạm_vi và đối_tượng áp_dụng cán_bộ công_chức viên_chức xếp lương theo bảng lương chuyên_gia cao_cấp các bảng lương chuyên_môn nghiệp_vụ thừa_hành phục_vụ làm_việc trong các ...\n\n2. Document ID: 40804\n   Score: 42.1669\n   Preview: điều đối_tượng áp_dụng cán_bộ công_chức viên_chức người lao_động trong các cơ_quan tổ_chức đơn_vị của đảng nhà_nước tổ_chức chính_trị xã_hội từ trung_ương đến xã_phường thị_trấn sau đây gọi chung là c...\n\n3. Document ID: 127461\n   Score: 42.0707\n   Preview: quan_điểm chỉ_đạo mục_tiêu và nội_dung cải_cách nội_dung cải_cách đối_với cán_bộ công_chức viên_chức và lực_lượng_vũ_trang khu_vực công_thiết_kế cơ_cấu tiền_lương mới gồm lương cơ_bản chiếm khoảng tổn...\n\n4. Document ID: 102151\n   Score: 41.6448\n   Preview: phạm_vi và đối_tượng áp_dụng cán_bộ công_chức kể_cả công_chức dự_bị viên_chức những người đang trong thời_gian tập_sự thử việc và lao_động hợp_đồng đã được xếp lương theo bảng lương do nhà_nước quy_đị...\n\n5. Document ID: 138893\n   Score: 39.7046\n   Preview: nội_dung cải_cách đối_với cán_bộ công_chức viên_chức và lực_lượng_vũ_trang khu_vực công xây_dựng ban_hành hệ_thống bảng lương mới theo vị_trí việc_làm chức_danh và chức_vụ lãnh_đạo thay_thế hệ_thống b...\n\n6. Document ID: 68359\n   Score: 39.2045\n   Preview: phụ_cấp lương phụ_cấp chức_vụ lãnh_đạo cán_bộ cấp xã tốt_nghiệp trình_độ đào_tạo chuyên_môn nghiệp_vụ từ trung_cấp trở lên đã được xếp lương theo ngạch bậc công_chức hành_chính quy_định tại khoản điều...\n\n7. Document ID: 156700\n   Score: 37.6426\n   Preview: những người làm_việc các địa_bàn đảo xa đất_liền và vùng biên_giới có điều_kiện sinh_hoạt đặc_biệt khó_khăn quy_định tại phụ_lục ban_hành kèm theo thông_tư này được hưởng phụ_cấp đặc_biệt gồm sĩ_quan ...\n\n8. Document ID: 85688\n   Score: 37.6426\n   Preview: phạm_vi và đối_tượng phạm_vi và đối_tượng áp_dụng cán_bộ công_chức viên_chức và người lao_động xếp_ương theo các bảng_ương chuyên_môn nghiệp_vụ thừa_hành phục_vụ làm_việc trong các cơ_quan nhà_nước từ...\n\n9. Document ID: 122844\n   Score: 37.6426\n   Preview: phụ_cấp công_tác đảng đoàn_thể chính_trị xã_hội phạm_vi và đối_tượng áp_dụng phạm_vi áp_dụng hướng_dẫn này quy_định về chế_độ phụ_cấp công_tác đảng đoàn_thể chính_trị xã_hội đối_với cán_bộ công_chức v...\n\n10. Document ID: 62830\n   Score: 36.0100\n   Preview: đối_với cán_bộ cấp xã cán_bộ cấp xã có trình_độ sơ_cấp hoặc chưa đào_tạo trình_độ chuyên_môn nghiệp_vụ thực_hiện xếp lương chức_vụ theo bảng lương sau đây cán_bộ cấp xã đã tốt_nghiệp trình_độ đào_tạo ...\n\n11. Document ID: 19280\n   Score: 35.9771\n   Preview: điều kiêm_nhiệm chức_danh và mức phụ_cấp kiêm_nhiệm chức_danh chỉ bố_trí cán_bộ cấp xã kiêm_nhiệm chức_danh công_chức cấp xã khi cán_bộ cấp xã đáp_ứng đủ điều_kiện tiêu_chuẩn của chức_danh công_chức c...\n\n12. Document ID: 169691\n   Score: 35.9771\n   Preview: điều xếp lương đối_với công_chức cấp xã công_chức cấp xã tốt_nghiệp trình_độ đào_tạo từ sơ_cấp trở lên phù_hợp với chuyên_môn của chức_danh đảm_nhiệm thực_hiện xếp lương như công_chức hành_chính quy_đ...\n\n13. Document ID: 68242\n   Score: 35.7498\n   Preview: điều cán_bộ công_chức được bầu_cử vào các chức_vụ hoặc được bổ_nhiệm giữ các chức_vụ lãnh_đạo trong các cơ_quan nhà_nước tổ_chức chính_trị tổ_chức chính_tri xã_hội và chuyên_gia cao_cấp được hưởng chế...\n\n14. Document ID: 8118\n   Score: 34.9346\n   Preview: cán_bộ công_chức viên_chức và người làm_việc theo chế_độ hợp_đồng lao_động kể_cả người tập_sự thử việc trong các cơ_quan tổ_chức đơn_vị sự_nghiệp của đảng nhà_nước tổ_chức chính_trị xã_hội quy_định tạ...\n\n15. Document ID: 38714\n   Score: 34.9346\n   Preview: điều đối_tượng áp_dụng cán_bộ công_chức người hưởng lương hoặc phụ_cấp quân_hàm từ ngân_sách nhà_nước quy_định tại điều nghị_định này bao_gồm cán_bộ theo quy_định tại khoản điều_luật cán_bộ công_chức ...\n\n16. Document ID: 188511\n   Score: 34.9346\n   Preview: nhiệm_vụ và quyền_hạn vụ tiền_lương tham_mưu giúp bộ_trưởng bộ nội_vụ thực_hiện các nhiệm_vụ quyền_hạn sau đây trình bộ_trưởng ban_hành các văn_bản hướng_dẫn thực_hiện quy_định của chính_phủ thủ_tướng...\n\n17. Document ID: 63324\n   Score: 34.9346\n   Preview: phạm_vi và đối_tượng đối_tượng không áp_dụng cán_bộ thuộc diện xếp lương theo bảng lương chức_vụ đã được xếp lương theo nhiệm_kỳ cán_bộ cấp xã là người đang hưởng chế_độ hưu_trí hoặc trợ_cấp mất sức_l...\n\n18. Document ID: 118421\n   Score: 34.7926\n   Preview: điều xếp lương đối_với cán_bộ cấp xã cán_bộ cấp xã có trình_độ sơ_cấp hoặc chưa đào_tạo trình_độ chuyên_môn nghiệp_vụ thực_hiện xếp lương chức_vụ theo bảng lương sau đây\n\n19. Document ID: 140864\n   Score: 34.3796\n   Preview: áp_dụng chế_độ tiền_lương và phụ_cấp quy_định tại nghị_định số cp ngày_tháng năm của chính_phủ quy_định tạm_thời chế_độ tiền_lương mới trong các doanh_nghiệp nhà_nước đối_với cán_bộ viên_chức ngân_hàn...\n\n20. Document ID: 11095\n   Score: 34.3796\n   Preview: điều quy_định về tiêu_chuẩn chi một_số khoản chi công_tác phí được phân_thành tiêu_chuẩn chi như sau tiêu_chuẩn để thanh_toán cho các cán_bộ công_chức thuộc các chức_danh lãnh_đạo sau đây tổng_bí_thư ...\n","output_type":"stream"}],"execution_count":20}]}